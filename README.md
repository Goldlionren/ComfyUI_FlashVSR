# ğŸš€ ComfyUI FlashVSR (Goldlionren Edition)

> Enhanced version of [smthemex/ComfyUI_FlashVSR](https://github.com/smthemex/ComfyUI_FlashVSR)  
> by [Goldlionren](https://github.com/Goldlionren), featuring **dual-GPU CUDA support**, **multi-device safe memory logic**, and **v11 compatibility**.

---

## âœ¨ What's New (2025-11)

âœ… **Dual-GPU CUDA decoding**  
- Added logic for automatic fallback between `cuda:0` and `cuda:1`  
- Prevented cross-device tensor mismatches  
- Ensures stable decoding even when out of GPU memory  

âœ… **Improved TCDecoder memory logic**  
- Safe cross-device memory reuse  
- Adds CPU fallback for out-of-memory stacking  
- Eliminates device mismatch crashes  

âœ… **v11-compatible infer scripts**  
- Updated:  
  - `infer_flashvsr_v11_full.py`  
  - `infer_flashvsr_v11_tiny.py`  
- Based on upstream `v11` structure but retains Goldlionrenâ€™s multi-GPU logic  

âœ… **Clean upstream sync (Nov 2025)**  
- Integrated the latest changes from `smthemex/main`  
- Clean rebase and code merge with conflict resolution  

---

## ğŸ”§ Installation

Clone the latest **dual-GPU** branch:

```bash
git clone -b cuda_dual_gpu_v1_1 --single-branch https://github.com/Goldlionren/ComfyUI_FlashVSR.git
```

For Intel XPU users (Arc / iGPU), use the `XPU_v1.0` branch:

```bash
git clone -b XPU_v1.0 --single-branch https://github.com/Goldlionren/ComfyUI_FlashVSR.git
```

Then place the folder under your ComfyUI `custom_nodes` directory:
```
ComfyUI/custom_nodes/ComfyUI_FlashVSR
```

---

## âš™ï¸ Requirements

- Python â‰¥ 3.10  
- PyTorch â‰¥ 2.7.0 + CUDA 12.4  
- Compatible with:
  - NVIDIA RTX 40xx Series  
  - Dual-GPU systems (tested on RTX 4080 SUPER + 4060 Ti)  
  - Intel XPU (Arc A770 / A770M) via `XPU_v1.0` branch  

---

## ğŸ“‚ Branch Summary

| Branch | Description |
|--------|--------------|
| `main` | Upstream base (synced with smthemex) |
| `XPU_v1.0` | Intel XPU build (Arc A770 / A770M) |
| `cuda_dual_gpu_v1_1` | NVIDIA dual-GPU build (v11 integration, stable) |

---

## ğŸ§  Technical Notes

- `TCDecoder.py` now includes robust device safety:
  - Automatically reinitializes tensors when device mismatch detected  
  - Supports CPU fallback when GPU memory exhausted  
  - Ensures consistent decode state across re-runs  

- `infer_flashvsr_full.py` / `infer_flashvsr_tiny.py` now:
  - Detect GPU availability dynamically  
  - Retry decode on secondary device  
  - Integrate ComfyUI prompt parameters for flexible inference  

---

## ğŸ‡¨ğŸ‡³ ä¸­æ–‡è¯´æ˜

æœ¬åˆ†æ”¯ä¸ºåœ¨ ComfyUI ä¸Šè¿è¡Œ FlashVSR çš„ **å¢å¼ºç‰ˆ**ï¼Œä¸»è¦æ”¹è¿›åŒ…æ‹¬ï¼š

- **åŒæ˜¾å¡è‡ªåŠ¨åˆ†æ‹…è§£ç ä»»åŠ¡**ï¼ˆCUDA ç‰ˆæœ¬ï¼‰  
- **æ˜¾å­˜ä¸è¶³è‡ªåŠ¨å›é€€æœºåˆ¶**  
- **è·¨è®¾å¤‡å®‰å…¨å†…å­˜ç®¡ç†ï¼ˆTCDecoder ä¿®å¤ï¼‰**  
- **å…¼å®¹ FlashVSR v11 çš„æ–°ç‰ˆæ¨ç†è„šæœ¬**  
- å·²åŒæ­¥åŸä½œè€…ä»“åº“ 2025 å¹´ 11 æœˆæ›´æ–°å†…å®¹  

---

## ğŸ§© Maintainer

**Goldlionren**  
ğŸ“¦ Repo: [https://github.com/Goldlionren/ComfyUI_FlashVSR](https://github.com/Goldlionren/ComfyUI_FlashVSR)
